import os
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import streamlit as st
import pandas as pd
import networkx as nx
import json
import logging
import re
from analysis.clustering import add_clusters_to_metrics
from analysis.graph_builder import build_graph_from_messages
from analysis.graph_viz_plotly import plot_graph
from analysis.predictor import get_isolation_predictions
from analysis.llm_analyzer import analyze_with_llm

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

st.set_page_config(page_title="VK InsightGraph", layout="wide")
st.markdown("""
    <style>
    .stApp, [data-testid="stSidebar"] {
        background-color: #424242 !important;
        color: #000000 !important;
    }
    .main {
        padding: 2rem;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);
    }
    .vk-logo {
        position: absolute;
        top: 10px;
        left: 10px;
        font-size: 2rem;
        color: #BBDEFB;
    }
    h1 {
        color: #BBDEFB !important;
        font-weight: 700;
        margin-bottom: 0.5rem;
        margin-left: 40px;
    }
    h2 {
        color: #90CAF9 !important;
        font-size: 1.5rem;
        margin-top: 2rem;
        padding-bottom: 0.5rem;
        border-bottom: 2px solid #616161;
    }
    .stMarkdown, .stMarkdown p, .stMarkdown div, .stText, .stTextInput input, .stSelectbox, .stMultiselect, .stCheckbox label {
        color: #000000 !important;
        font-size: 1rem;
        line-height: 1.6;
    }
    [data-testid="stSidebar"] {
        background-color: #616161 !important;
        padding: 1.5rem;
    }
    .stButton button {
        background-color: #90CAF9 !important;
        color: #000000 !important;
        border-radius: 5px;
        padding: 0.5rem 1rem;
        transition: background-color 0.2s;
        border: 1px solid #BBDEFB !important;
    }
    .stButton button:hover {
        background-color: #BBDEFB !important;
        color: #000000 !important;
    }
    .stDataFrame table {
        border-collapse: collapse;
        width: 100%;
        color: #000000 !important;
        background-color: #757575 !important;
    }
    .stDataFrame th {
        background-color: #616161 !important;
        color: #BBDEFB !important;
        font-weight: 600;
    }
    .stDataFrame tr:nth-child(even) {
        background-color: #424242 !important;
    }
    .stDataFrame td, .stDataFrame th {
        padding: 0.75rem;
        border: 1px solid #616161;
    }
    .recommendation-card {
        background-color: #616161 !important;
        padding: 1rem;
        border-radius: 8px;
        margin-bottom: 1rem;
        border-left: 4px solid #90CAF9;
        color: #000000 !important;
    }
    .stPlotlyChart {
        background-color: #424242 !important;
        border-radius: 8px;
        padding: 1rem;
        min-height: 700px !important;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);
    }
    .stTabs [role="tab"] {
        color: #B0BEC5 !important;
        font-weight: 500;
    }
    .stTabs [role="tab"][aria-selected="true"] {
        color: #BBDEFB !important;
        border-bottom: 2px solid #90CAF9 !important;
    }
    </style>
    <div class="vk-logo">‚ò∞</div>
""", unsafe_allow_html=True)

st.title("üìä VK InsightGraph ‚Äî –ê–Ω–∞–ª–∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π –¥–∏–Ω–∞–º–∏–∫–∏")
st.markdown("""
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏ –≤ VK Teams: –≤—ã—è–≤–ª—è–π—Ç–µ –≥—Ä—É–ø–ø—ã –æ–±—â–µ–Ω–∏—è, –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –∏ –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –ª–∏–¥–µ—Ä–æ–≤.

**–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å**:
1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV/JSON —Å –¥–∞–Ω–Ω—ã–º–∏ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–π (–ø—Ä–∏–º–µ—Ä: `mini_messages.csv`).
2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–∏–ª—å—Ç—Ä—ã –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏, —á—Ç–æ–±—ã –≤—ã–±—Ä–∞—Ç—å –æ—Ç–¥–µ–ª—ã, –≥—Ä—É–ø–ø—ã –∏–ª–∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤.
3. –ü–µ—Ä–µ–∫–ª—é—á–∞–π—Ç–µ—Å—å –º–µ–∂–¥—É –≤–∫–ª–∞–¥–∫–∞–º–∏: **–°–æ–æ–±—â–µ–Ω–∏—è**, **–ó–≤–æ–Ω–∫–∏**, **–í—Å—Ç—Ä–µ—á–∏**.
4. –ù–∞–∂–º–∏—Ç–µ **–°–∫–∞—á–∞—Ç—å –≥—Ä–∞—Ñ –∫–∞–∫ PNG** –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏.
""")

@st.cache_data
def load_data(uploaded_file, dashboard_path, parent_path):
    if uploaded_file is not None:
        if uploaded_file.name.endswith('.csv'):
            try:
                df = pd.read_csv(uploaded_file, on_bad_lines='warn')
                logger.info("CSV loaded successfully")
                return df
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ CSV: {str(e)}")
                return None
        else:
            try:
                data = json.load(uploaded_file)
                df = pd.DataFrame(data)
                logger.info("JSON loaded successfully")
                return df
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ JSON: {str(e)}")
                return None
    else:
        if os.path.exists(dashboard_path):
            try:
                df = pd.read_csv(dashboard_path, on_bad_lines='warn')
                logger.info("Default CSV loaded from dashboard directory")
                return df
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ default CSV from dashboard: {str(e)}")
                return None
        elif os.path.exists(parent_path):
            try:
                df = pd.read_csv(parent_path, on_bad_lines='warn')
                logger.info("Default CSV loaded from parent directory")
                return df
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ default CSV from parent: {str(e)}")
                return None
        else:
            st.error("–ù–µ –Ω–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã mini_messages.csv –≤ dashboard –∏–ª–∏ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –≤—Ä—É—á–Ω—É—é.")
            return None

with st.sidebar:
    st.header("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ JSON (sender, receiver, timestamp, channel)", type=["csv", "json"])

script_dir = os.path.dirname(os.path.abspath(__file__))
dashboard_path = os.path.join(script_dir, "mini_messages.csv")
parent_path = os.path.join(script_dir, "..", "mini_messages.csv")
df = load_data(uploaded_file, dashboard_path, parent_path)

if df is None:
    st.stop()

required_columns = ['sender', 'receiver', 'timestamp']
if not all(col in df.columns for col in required_columns):
    st.error("–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏: sender, receiver, timestamp")
    st.stop()

if 'channel' not in df.columns:
    df['channel'] = 'message'
    logger.info("Added 'channel' column with default 'message'")

if 'call_duration' in df.columns:
    df['call_duration'] = df['call_duration'].where(df['channel'] == 'call', 0)
    logger.info("Filled missing 'call_duration' with 0 for non-call records")

@st.cache_data
def enrich_metrics_with_departments(df, metrics):
    departments = {}
    for _, row in df.iterrows():
        departments[row['sender']] = row.get('sender_department', 'Unknown')
        departments[row['receiver']] = row.get('receiver_department', 'Unknown')
    metrics['department'] = metrics['user'].map(departments).fillna('Unknown')
    return metrics

@st.cache_resource
def build_graph_cached(df, weight_col=None, export_metrics=False):
    return build_graph_from_messages(df, weight_col, export_metrics)

df_messages = df[df['channel'] == 'message'].copy()
df_calls = df[df['channel'] == 'call'].copy()

try:
    G_messages = build_graph_cached(df_messages)
    logger.info(f"G_messages created with {len(G_messages.nodes())} nodes and {len(G_messages.edges())} edges")
    metrics_messages = build_graph_cached(df_messages, export_metrics=True)
    logger.info(f"metrics_messages shape: {metrics_messages.shape}")
    metrics_messages = enrich_metrics_with_departments(df, metrics_messages)
    logger.info(f"metrics_messages departments: {metrics_messages['department'].unique().tolist()}")
    metrics_messages = add_clusters_to_metrics(G_messages, metrics_messages)
    logger.info(f"metrics_messages group_ids: {metrics_messages['group_id'].unique().tolist()}")
except Exception as e:
    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π: {str(e)}")
    st.stop()

try:
    G_calls = build_graph_cached(df_calls, weight_col='call_duration')
    logger.info(f"G_calls created with {len(G_calls.nodes())} nodes and {len(G_calls.edges())} edges")
    metrics_calls = build_graph_cached(df_calls, weight_col='call_duration', export_metrics=True)
    metrics_calls = enrich_metrics_with_departments(df, metrics_calls)
    metrics_calls = add_clusters_to_metrics(G_calls, metrics_calls)
except Exception as e:
    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö –∑–≤–æ–Ω–∫–æ–≤: {str(e)}")
    metrics_calls = pd.DataFrame()

with st.sidebar:
    st.header("üîç –§–∏–ª—å—Ç—Ä—ã")
    if 'group_filter' not in st.session_state:
        st.session_state.group_filter = metrics_messages['group_id'].unique().tolist()
    if 'department_filter' not in st.session_state:
        st.session_state.department_filter = metrics_messages['department'].unique().tolist()
    if 'show_isolated' not in st.session_state:
        st.session_state.show_isolated = False
    if 'show_overloaded' not in st.session_state:
        st.session_state.show_overloaded = False
    if 'show_bridges' not in st.session_state:
        st.session_state.show_bridges = False

    group_filter = st.multiselect("–ì—Ä—É–ø–ø—ã –æ–±—â–µ–Ω–∏—è", sorted(metrics_messages['group_id'].unique()), default=st.session_state.group_filter, key="group_filter")
    department_filter = st.multiselect("–û—Ç–¥–µ–ª—ã", sorted(metrics_messages['department'].unique()), default=st.session_state.department_filter, key="department_filter")
    show_isolated = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö", value=st.session_state.show_isolated, key="show_isolated")
    show_overloaded = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö", value=st.session_state.show_overloaded, key="show_overloaded")
    show_bridges = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ —Å–≤—è–∑—É—é—â–∏—Ö", value=st.session_state.show_bridges, key="show_bridges")
    
    if st.button("–°–±—Ä–æ—Å–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä—ã"):
        st.session_state.group_filter = metrics_messages['group_id'].unique().tolist()
        st.session_state.department_filter = metrics_messages['department'].unique().tolist()
        st.session_state.show_isolated = False
        st.session_state.show_overloaded = False
        st.session_state.show_bridges = False
        st.rerun()

filtered_metrics = metrics_messages.copy()
if group_filter:
    filtered_metrics = filtered_metrics[filtered_metrics['group_id'].isin(group_filter)]
if department_filter:
    filtered_metrics = filtered_metrics[filtered_metrics['department'].isin(department_filter)]
if show_isolated:
    filtered_metrics = filtered_metrics[filtered_metrics['is_isolated']]
if show_overloaded:
    filtered_metrics = filtered_metrics[filtered_metrics['is_overloaded']]
if show_bridges:
    filtered_metrics = filtered_metrics[filtered_metrics['is_bridge']]
logger.info(f"Filtered metrics users: {filtered_metrics['user'].tolist()}")

tab1, tab2, tab3 = st.tabs(["üì© –°–æ–æ–±—â–µ–Ω–∏—è", "üìû –ó–≤–æ–Ω–∫–∏", "üóìÔ∏è –í—Å—Ç—Ä–µ—á–∏"])

with tab1:
    st.subheader("üì© –ê–Ω–∞–ª–∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π")
    st.markdown("–£–∑–Ω–∞–π—Ç–µ, –∫–∞–∫ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ –æ–±—â–∞—é—Ç—Å—è –≤ —á–∞—Ç–∞—Ö VK Teams.")
    try:
        group_summary = metrics_messages.groupby('group_id').agg({
            'user': 'count',
            'degree': 'mean',
            'clustering': 'mean',
            'department': lambda x: x.mode()[0] if not x.empty else 'Unknown'
        }).rename(columns={'user': 'count', 'department': 'main_department'})
        st.dataframe(group_summary.rename(columns={
            'count': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤',
            'degree': '–°—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å',
            'clustering': '–ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Å–≤—è–∑–µ–π',
            'main_department': '–û—Å–Ω–æ–≤–Ω–æ–π –æ—Ç–¥–µ–ª'
        }), use_container_width=True)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ group_summary: {str(e)}")

    st.markdown("**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≥—Ä—É–ø–ø–∞–º**:")
    for group_id in group_summary.index:
        count = group_summary.loc[group_id, 'count']
        mean_degree = group_summary.loc[group_id, 'degree']
        main_dept = group_summary.loc[group_id, 'main_department']
        if count <= 2:
            st.markdown(f"<div class='recommendation-card'>–ì—Ä—É–ø–ø–∞ {group_id} ({main_dept}, {count} —á–µ–ª.): –ú–∞–ª–æ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤, –¥–æ–±–∞–≤—å—Ç–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤.</div>", unsafe_allow_html=True)
        elif mean_degree < metrics_messages['degree'].mean():
            st.markdown(f"<div class='recommendation-card'>–ì—Ä—É–ø–ø–∞ {group_id} ({main_dept}, {count} —á–µ–ª.): –ù–∏–∑–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å, –∏–Ω–∏—Ü–∏–∏—Ä—É–π—Ç–µ –æ–±—Å—É–∂–¥–µ–Ω–∏—è.</div>", unsafe_allow_html=True)

    st.markdown("**–ö–ª—é—á–µ–≤—ã–µ —Å–≤—è–∑—É—é—â–∏–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏**:")
    bridges = metrics_messages[metrics_messages['is_bridge']]
    for user in bridges['user']:
        st.markdown(f"<div class='recommendation-card'>{user}: –°–≤—è–∑—É—é—â–∏–π —Å–æ—Ç—Ä—É–¥–Ω–∏–∫, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å.</div>", unsafe_allow_html=True)

    st.subheader("üß† –ò–Ω—Å–∞–π—Ç—ã –æ—Ç –ò–ò (—Å–æ–æ–±—â–µ–Ω–∏—è)")
    try:
        llm_recommendations = analyze_with_llm(group_summary, metrics_messages, analysis_type="messages")
        st.markdown(f"<div class='recommendation-card'>{llm_recommendations}</div>", unsafe_allow_html=True)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –≤ –∞–Ω–∞–ª–∏–∑–µ –ò–ò: {str(e)}")

    st.subheader("üï∏Ô∏è –ì—Ä–∞—Ñ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–π")
    if filtered_metrics.empty:
        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∞ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.")
    else:
        users_to_plot = filtered_metrics['user'].tolist()
        department_colors = {
            'IT': '#64B5F6',
            'Finance': '#FFCA28',
            'Sales': '#4CAF50',
            'HR': '#EF5350',
            'Marketing': '#AB47BC',
            'Unknown': '#B0BEC5'
        }
        if not users_to_plot:
            st.warning("–ù–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥—Ä–∞—Ñ–∞ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.")
        elif not G_messages.nodes():
            st.warning("–ì—Ä–∞—Ñ –ø—É—Å—Ç: –Ω–µ—Ç —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏.")
        else:
            try:
                logger.info(f"Plotting graph with {len(users_to_plot)} users")
                fig = plot_graph(G_messages, filtered_metrics, users_to_plot, department_colors)
                if fig.data:
                    st.plotly_chart(fig, use_container_width=True, key=f"graph_{hash(tuple(users_to_plot))}")
                    if st.button("–°–∫–∞—á–∞—Ç—å –≥—Ä–∞—Ñ –∫–∞–∫ PNG"):
                        fig.write_image("graph.png")
                        with open("graph.png", "rb") as file:
                            st.download_button("–°–∫–∞—á–∞—Ç—å PNG", file, "graph.png")
                else:
                    st.warning("–ù–µ—Ç —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä—ã.")
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ –≥—Ä–∞—Ñ–∞: {str(e)}")
                logger.error(f"Graph plotting error: {str(e)}", exc_info=True)

with tab2:
    st.subheader("üîç –ê–Ω–∞–ª–∏–∑ –∑–≤–æ–Ω–∫–æ–≤")
    st.markdown("–£–∑–Ω–∞–π—Ç–µ, –∫–∞–∫ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É—é—Ç —á–µ—Ä–µ–∑ –≤–∏–¥–µ–æ–∑–≤–æ–Ω–∫–∏ VK Teams.")
    if metrics_calls.empty:
        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –∑–≤–æ–Ω–∫–∞—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
    else:
        try:
            group_summary_calls = metrics_calls.groupby('group_id').agg({
                'user': 'count',
                'degree': 'mean',
                'clustering': 'mean',
                'department': lambda x: x.mode()[0] if not x.empty else 'Unknown'
            }).rename(columns={'user': 'count', 'department': 'main_department'})
            st.dataframe(group_summary_calls.rename(columns={
                'count': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤',
                'degree': '–°—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (–∑–≤–æ–Ω–∫–∏)',
                'clustering': '–ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Å–≤—è–∑–µ–π',
                'main_department': '–û—Å–Ω–æ–≤–Ω–æ–π –æ—Ç–¥–µ–ª'
            }), use_container_width=True)
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ group_summary_calls: {str(e)}")

        st.markdown("**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∑–≤–æ–Ω–∫–∞–º**:")
        if not group_summary_calls.empty:
            for group_id in group_summary_calls.index:
                count = group_summary_calls.loc[group_id, 'count']
                mean_degree = group_summary_calls.loc[group_id, 'degree']
                main_dept = group_summary_calls.loc[group_id, 'main_department']
                if count <= 2:
                    st.markdown(f"<div class='recommendation-card'>–ì—Ä—É–ø–ø–∞ {group_id} ({main_dept}, {count} —á–µ–ª.): –ú–∞–ª–æ –∑–≤–æ–Ω–∫–æ–≤, –æ—Ä–≥–∞–Ω–∏–∑—É–π—Ç–µ –≤–∏–¥–µ–æ–≤—Å—Ç—Ä–µ—á–∏.</div>", unsafe_allow_html=True)
                elif mean_degree < metrics_calls['degree'].mean():
                    st.markdown(f"<div class='recommendation-card'>–ì—Ä—É–ø–ø–∞ {group_id} ({main_dept}, {count} —á–µ–ª.): –ù–∏–∑–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∑–≤–æ–Ω–∫–æ–≤, –ø—Ä–µ–¥–ª–æ–∂–∏—Ç–µ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ —Å–æ–∑–≤–æ–Ω—ã.</div>", unsafe_allow_html=True)

        st.markdown("**–ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∑–≤–æ–Ω–∫–æ–≤**:")
        bridges = metrics_calls[metrics_calls['is_bridge']]
        for user in bridges['user']:
            st.markdown(f"<div class='recommendation-card'>–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç–µ –∑–≤–æ–Ω–∫–∏ –Ω–∞ {user}: —Å–≤—è–∑—É—é—â–∏–π —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–æ–º–∞–Ω–¥.</div>", unsafe_allow_html=True)

        st.subheader("üß† –ò–Ω—Å–∞–π—Ç—ã –æ—Ç –ò–ò (–∑–≤–æ–Ω–∫–∏)")
        try:
            llm_recommendations = analyze_with_llm(group_summary_calls, metrics_calls, analysis_type="calls")
            st.markdown(f"<div class='recommendation-card'>{llm_recommendations}</div>", unsafe_allow_html=True)
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –≤ –∞–Ω–∞–ª–∏–∑–µ –ò–ò: {str(e)}")

with tab3:
    st.subheader("üóìÔ∏è –ü–æ–¥—Å–∫–∞–∑–∫–∏ –¥–ª—è –≤—Å—Ç—Ä–µ—á")
    st.markdown("–ò–ò –ø–æ–º–æ–∂–µ—Ç –≤—ã–±—Ä–∞—Ç—å —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –¥–ª—è –≤—Å—Ç—Ä–µ—á –≤ –∫–∞–ª–µ–Ω–¥–∞—Ä–µ VK WorkSpace.")
    try:
        llm_meeting_suggestions = analyze_with_llm(group_summary, metrics_messages, analysis_type="meetings")
        st.markdown(f"<div class='recommendation-card'>{llm_meeting_suggestions}</div>", unsafe_allow_html=True)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –≤ –∞–Ω–∞–ª–∏–∑–µ –ò–ò: {str(e)}")

st.subheader("üìù –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
if filtered_metrics.empty:
    st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.")
else:
    isolated = filtered_metrics[filtered_metrics['is_isolated']]
    overloaded = filtered_metrics[filtered_metrics['is_overloaded']]
    bridges = filtered_metrics[filtered_metrics['is_bridge']]

    if not isolated.empty:
        st.markdown("**–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏**:")
        for user in isolated['user']:
            st.markdown(f"<div class='recommendation-card'>{user}: –£–≤–µ–ª–∏—á—å—Ç–µ –≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ –≤—Å—Ç—Ä–µ—á–∏.</div>", unsafe_allow_html=True)
    if not overloaded.empty:
        st.markdown("**–ü–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏**:")
        for user in overloaded['user']:
            st.markdown(f"<div class='recommendation-card'>{user}: –î–µ–ª–µ–≥–∏—Ä—É–π—Ç–µ –∑–∞–¥–∞—á–∏ –∏–ª–∏ —Å–Ω–∏–∑–∏—Ç–µ –Ω–∞–≥—Ä—É–∑–∫—É.</div>", unsafe_allow_html=True)
    if not bridges.empty:
        st.markdown("**–ö–ª—é—á–µ–≤—ã–µ —Å–≤—è–∑—É—é—â–∏–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏**:")
        for user in bridges['user']:
            st.markdown(f"<div class='recommendation-card'>{user}: –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å, —Å–≤—è–∑—ã–≤–∞–µ—Ç –∫–æ–º–∞–Ω–¥—ã.</div>", unsafe_allow_html=True)

st.subheader("üîÆ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏–∑–æ–ª—è—Ü–∏–∏")
try:
    high_risk = get_isolation_predictions(metrics_messages)
    if not high_risk.empty:
        st.markdown("**–°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ —Å —Ä–∏—Å–∫–æ–º –∏–∑–æ–ª—è—Ü–∏–∏**:")
        for _, row in high_risk.iterrows():
            st.markdown(f"<div class='recommendation-card'>{row['user']}: –†–∏—Å–∫ –∏–∑–æ–ª—è—Ü–∏–∏ {row['isolation_risk']:.2%}</div>", unsafe_allow_html=True)
    else:
        st.markdown("<div class='recommendation-card'>–ù–µ—Ç —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —Å –≤—ã—Å–æ–∫–∏–º —Ä–∏—Å–∫–æ–º –∏–∑–æ–ª—è—Ü–∏–∏.</div>", unsafe_allow_html=True)
except Exception as e:
    st.error(f"–û—à–∏–±–∫–∞ –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö: {str(e)}")

st.subheader("üìà –ú–µ—Ç—Ä–∏–∫–∏ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤")
st.dataframe(
    filtered_metrics.sort_values(by="degree", ascending=False).reset_index(drop=True),
    use_container_width=True,
    height=500
)

with st.sidebar:
    st.header("üîé –ü–æ–∏—Å–∫ —É—á–∞—Å—Ç–Ω–∏–∫–∞")
    search_name = st.text_input("–í–≤–µ–¥–∏—Ç–µ –∏–º—è (user_id)")
    if search_name:
        escaped_search = re.escape(search_name)
        result = metrics_messages[metrics_messages['user'].str.contains(escaped_search, case=False, na=False)]
        st.markdown(f"üîç –ù–∞–π–¥–µ–Ω–æ: {len(result)}")
        st.dataframe(result)
